{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorer les avertissements pour une sortie plus propre\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'transactions.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Drop unnecessary column\n",
    "#df = df.drop('Unnamed: 0', axis=1)\n",
    "# Check for empty columns\n",
    "empty_cols = df.columns[df.isnull().all()]\n",
    "if not empty_cols.empty:\n",
    "    # Remove empty columns\n",
    "    df = df.drop(empty_cols, axis=1)\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['prix_m2'] = df['prix'] / df['surface_habitable']\n",
    "\n",
    "# Filter for transactions in Paris in 2022\n",
    "paris_df = df[(df.departement == 75) & (df.date_transaction.str.startswith('2022-'))].copy()\n",
    "\n",
    "# Process surface columns\n",
    "surface_cols = [c for c in paris_df.columns if 'surface_' in c and c != 'surface_habitable']\n",
    "for c in surface_cols:\n",
    "    paris_df[c + '_sum'] = paris_df[c].apply(lambda x: sum(eval(x)) if 'NULL' not in x else 0)\n",
    "    \n",
    "# Filter rows where the sum of surface columns is 0\n",
    "paris_df = paris_df[paris_df[[c + '_sum' for c in surface_cols]].sum(axis=1) == 0]\n",
    "\n",
    "# Convert date_transaction to datetime and calculate days since epoch\n",
    "paris_df['date_transaction'] = pd.to_datetime(paris_df['date_transaction'])\n",
    "reference_date = pd.to_datetime('1970-01-01')\n",
    "paris_df['days_since_epoch'] = (paris_df['date_transaction'] - reference_date).dt.days\n",
    "\n",
    "# Drop the original date_transaction column\n",
    "paris_df = paris_df.drop('date_transaction', axis=1)\n",
    "\n",
    "# Create dummy variables for type_batiment\n",
    "paris_df = pd.get_dummies(paris_df, columns=['type_batiment'], prefix='type')\n",
    "\n",
    "# Select relevant features for X and y\n",
    "X = paris_df[['days_since_epoch', 'longitude', 'latitude', 'id_ville', 'type_Appartement', 'type_Maison', 'vefa', 'n_pieces', 'surface_habitable']]\n",
    "y = paris_df['prix_m2']\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Save the processed DataFrame to a new file\n",
    "dataset_file_path = 'dataset.csv'\n",
    "paris_df.to_csv(dataset_file_path, index=False)\n",
    "\n",
    "dataset_file_path\n",
    "\n",
    "# Division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grille des paramètres pour la recherche\n",
    "params_grid = {\n",
    "    'DTR': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': range(1, 101, 10),\n",
    "            'min_samples_split': range(2, 21, 2)\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {\n",
    "            'n_neighbors': range(1, 51, 5)\n",
    "        }\n",
    "    },\n",
    "    'LR': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {\n",
    "            'fit_intercept': [True, False],\n",
    "            'positive': [True, False]\n",
    "        }\n",
    "    },\n",
    "    'RFR': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': range(10, 111, 10),\n",
    "            'min_samples_leaf': range(1, 12, 2),\n",
    "            'n_estimators': [100, 200, 300, 400, 500]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Entraînement des modèles avec validation croisée\n",
    "best_models = {}  # Dictionnaire pour stocker les meilleurs modèles\n",
    "\n",
    "for model_name, model_config in tqdm(params_grid.items()):\n",
    "    gs = GridSearchCV(estimator=model_config\n",
    "['model'], param_grid=model_config['params'])\n",
    "gs.fit(X_train, y_train)\n",
    "best_model = gs.best_estimator_\n",
    "best_params = gs.best_params_\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, best_model.predict(X_train)))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, best_model.predict(X_test)))\n",
    "score = best_model.score(X_test, y_test)\n",
    "# Enregistrement du meilleur modèle\n",
    "best_models[model_name] = {\n",
    "    'model': best_model,\n",
    "    'params': best_params,\n",
    "    'train_rmse': train_rmse,\n",
    "    'test_rmse': test_rmse,\n",
    "    'score': score\n",
    "}\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Optimal params: {best_params}\")\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n",
    "print(f\"Model Score: {score}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entraînement automatique du meilleur modèle trouvé\n",
    "best_model_name = max(best_models, key=lambda k: best_models[k]['score'])\n",
    "best_model_to_train = best_models[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nEntraînement automatique du meilleur modèle trouvé ({best_model_name}) avec les meilleurs paramètres...\")\n",
    "best_model_to_train.fit(X, y) # Utilisation de l'ensemble complet pour l'entraînement\n",
    "print(\"Entraînement terminé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
